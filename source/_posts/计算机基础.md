---
title: 计算机基础
date: 2018-12-22 22:46:19
tags: 计算机基础
categories: 基础
toc: true
keywords: 
description: 计算机基础
comments: 
---

# 字符集

> 计算机只能处理数字，如果要处理文本，就必须先把文本转换为数字才能处理。Unicode把所有语言都统一到一套编码里，这样就不会再有乱码问题了。Unicode标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要4个字节）。现代操作系统和大多数编程语言都直接支持Unicode。

计算机中的数据都是以二进制形式进行存储的，早期计算机只支持ASCII码。

ASCII码我们知道，是使用一个字节（8位二进制）来表示字符的。

那计算机使用ASCII编码格式来进行处理字符，即一个字节表示一个字符，下图是ASCII码表

![ASCII码表](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/0.8824667767621577.png)

> 例如：空格space，十进制位32，二进制00100000

ASCII码是使用一个字节来表示字符的，二进制表示它最大支持256个字符，ASCII码取正整数的128个数字来对应表示英文字母和一些常用字符，这个标准最早是美国人发明的，从现在来看它远远不够，比如说，光光中文就有几万个字符，所以各个国家都制定自己都标准。

世界上存在很多种编码方式，同一个二进制数字可以被解释成不同的的符号，当我们打开一个文本文件，就必须知道它的编码方式，不然会出现很多乱码字符。

为了解决这个问题，需要一个统一的标准，Unicode由此应运而生，它现在的规模就可以容纳100多万个字符，为世界上已知的所有文字都赋予一个独一无二的的编码。

**unicode只是一个字典，具体使用还是需要看各种字符集怎么使用**

unicode的表示的字符从2个字节到4个字节，那就出现一个问题，**计算机怎么去识别两个字节是一个字符或者二个字节是两个字符**？，**如果将所以字符都存储为4个字节的话，就会使数据大小急剧增加**。

**UTF-8**就是一种变长的编码方式，它可以使用1~4个字节表示一个符号，根据不同的符号而变化长度。

> 1\. 对于单字节的符号，字节的第一位为0，后面的7位就是这个符号的Unicode的码。
>
> 2\.  对于n字节的符号（n > 1），第一个字节的前n位都设为1，第n + 1位设为0，后面字节的前两位一律设为10。剩下的没有提及的二进制位，全部为这个符号的 Unicode 码。 



1. 第一位为0时，则这个字节单独就表示一个字符。
2. 获取一个字节，如果第一1，就继续往后读，有多少个1就是几个字节的字符。

> 举个列子: "严" 的unicode的编码是4E25（ 100111000100101 ），根据上面的转换逻辑，"严"的UTF-8的编码就是 11100100 10111000 10100101, 转换成十六进制就是E4B8A5 

# 进制

## 十进制

我们平时使用就是十进制，它是由0~9共十个数字组成第，它的计算规则是“逢十进一”

比如：8+5的结果，就是大于9，一个数字不够表示，这时只能进位，用13来表示；

## 二进制

它是由0和1，两个数字组成的。

学过计算机的人都知道，计算机中使用的是二进制，它的规则是“逢二进一”。

![img](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1A45323b-0.png)

如果想要使用二进制表示11这个数字，我们可以使用二进制从1开始加。

```
1+1 = 10 => 2

10 +1 = 11 => 3

11 + 1= 100 => 4

100 + 1 = 101 => 5

101 + 1 = 110 => 6

110 + 1 = 111 => 7

111 + 1 = 1000 => 8

1000 + 1 = 1001 => 9

1001 + 1 = 1010 => 10

1010 + 1 = 1011 => 11
```

## 八进制

它是由0~7共8个数字组成的，规则是逢八进一。

计算方法和其他的类似。

## 十六进制

它是由0~F共16个数字和字符组成的，规则是逢十六进一。

0~9和十进制一样，A表示10，B表示11，C表示12，D表示13，E表示14，F表示15。

## 进制之间的转换

### 目标十进制

二进制转换为十进制

```
11010 = 1×2^4 + 1×2^3 + 0×2^2 + 1×2^1 + 0×2^0 = 26（十进制）
```

八进制转换为十进制

```
53627 = 5×8^4 + 3×8^3 + 6×8^2 + 2×8^1 + 7×8^0 = 22423（十进制）
```

十六进制转换为十进制

```
9FA8C = 9×16^4 + 15×16^3 + 10×16^2 + 8×16^1 + 12×16^0 = 653964（十进制）
```

带小数(八进制转十进制)

```
423.5176 = 4×8^2 + 2×8^1 + 3×8^0 + 5×8^-1 + 1×8^-2 + 7×8^-3 + 6×8^-4 = 275.65576171875（十进制）
```

### 目标二进制

十进制转换为二进制

方法：使用十进制数进行除二取余数。

![img](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1AP56100-1.png)

小数部分

 十进制小数 0.6875 转换成二进制小数的过程： 



![img](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1AP5H92-3.png)





八进制转化为二进制

![image-20200219163422725](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/image-20200219163422725.png)



十六进制转化为二进制

和八进制一样，将没一位拆分成4位二进制。





### 目标八进制

十进制转化为八进制

![img](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1AP56143-0.png)

二进制转化为八进制

![image-20200219163508936](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/image-20200219163508936.png)

十六进制转化为八进制

先转化为而二进制，再转换为八进制





### 目标十六进制

二进制转化为十六进制

拆分法：

```
1001 1100 1111
 9     C    F

```



八进制转化为十六进制

先转化为二进制，在转化为十六进制



十进制转化为十六进制

十进制除以16，再取余。小数部分，乘以16取整。



# 原码反码和补码

### 原码

 将一个整数转换成二进制形式，就是其原码。例如`short a = 6;`，a 的原码就是`0000 0000 0000 0110`；更改 a 的值`a = -18;`，此时 a 的原码就是`1000 0000 0001 0010`。 

### 反码

谈到反码，正数和负数要区别对待，因为它们的反码不一样。

对于正数，它的反码就是其原码（原码和反码相同）；负数的反码是将原码中除符号位以外的所有位（数值位）取反，也就是 0 变成 1，1 变成 0。例如`short a = 6;`，a 的原码和反码都是`0000 0000 0000 0110`；更改 a 的值`a = -18;`，此时 a 的反码是`1111 1111 1110 1101`。 

### 补码

 正数和负数的补码也不一样，也要区别对待。

对于正数，它的补码就是其原码（原码、反码、补码都相同）；负数的补码是其反码加 1。例如`short a = 6;`，a 的原码、反码、补码都是`0000 0000 0000 0110`；更改 a 的值`a = -18;`，此时 a 的补码是`1111 1111 1110 1110`。

可以认为，补码是在反码的基础上打了一个补丁，进行了一下修正，所以叫“补码”。

原码、反码、补码的概念只对负数有实际意义，对于正数，它们都一样。

最后我们总结一下 6 和 -18 从原码到补码的转换过程： 

![img](%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/1121446295-0.jpg)

**在计算机内存中，整数一律采用补码的形式来存储。这意味着，当读取整数时还要采用逆向的转换，也就是将补码转换为原码。将补码转换为原码也很简单：先减去 1，再将数值位取反即可。** 



### 补码到底是如何简化硬件电路的

 假设 6 和 18 都是 short 类型的，现在我们要计算 6 - 18 的结果 

 如果采用**原码**计算，那么运算过程为： 

```
6 - 18 = 6 + (-18)
= [0000 0000 0000 0110]原 + [1000 0000 0001 0010]原
= [1000 0000 0001 1000]原
= -24 （很明显结果不对）
```

下面人才采用**反码**进行计算

```
6 - 18 = 6 + (-18)
= [0000 0000 0000 0110]反 + [1111 1111 1110 1101]反
= [1111 1111 1111 0011]反
= [1000 0000 0000 1100]原
= -12
```

结果是正确的。

但是是否适用于所有场景？

```
18 - 6 = 18 + (-6)
= [0000 0000 0001 0010]反 + [1111 1111 1111 1001]反
= [1 0000 0000 0000 1011]反 (第一位的1是加法的进位，它溢出了，内存容纳不了，所以截掉了)
= [0000 0000 0000 1011]反
= [0000 0000 0000 1011]原
= 11
```

 按照反码计算的结果是 11，而真实的结果应该是 12 才对，它们相差了 1。 

下面我们继续使用补码

```
6 - 18 = 6 + (-18)
= [0000 0000 0000 0110]补 + [1111 1111 1110 1110]补
= [1111 1111 1111 0100]补
=  [1111 1111 1111 0011]反
= [1000 0000 0000 1100]原
= -12

18 - 6 = 18 + (-6)
= [0000 0000 0001 0010]补 + [1111 1111 1111 1010]补
= [1 0000 0000 0000 1100]补
= [0000 0000 0000 1100]补
= [0000 0000 0000 1100]反
= [0000 0000 0000 1100]原
= 12

5 - 13 = 5 + (-13)
=  [0000 0000 0000 0101]补 + [1111 1111 1111 0011]补
= [1111 1111 1111 1000]补
= [1000 1111 1111 0111]反
= [1000 0000 0000 1000]原
= -8

13 - 5 = 13 + (-5)
= [0000 0000 0000 1101]补 + [1111 1111 1111 1011]补
= [1 0000 0000 0000 1000]补 
= [0000 0000 0000 1000]补
= [0000 0000 0000 1000]反
= [0000 0000 0000 1000]原
= 8
```

可以看出来所有的计算都真确了。



## 单位

位(bit)：又称为比特，是计算机中最小单位，即0或者1

字节(Byte)：是计算机的内存中基本单位

字：指在计算机中作为一个整体被存取、传送、处理的一组二进制数。一个字的位数（即字长）是计算机系统结构中的一个重要特性。字长是由CPU的类型所决定，不同的计算机系统的字长是不同的，常见的有8位、16位、32位、64位等，字长越长，计算机一次处理的信息位就越多，精度就越高，字长是计算机性能的一个重要指标，目前主流微机正在由32位机向64位机转变。

```c++
1Byte = 8bit

1KB (Kilobyte 千字节) = 1024B

1MB (Megabyte 兆字节 简称“兆”) = 1024KB

1GB (Gigabyte 吉字节 又称“千兆”) = 1024MB

1TB (Trillionbyte 万亿字节 太字节) = 1024GB 

1PB（Petabyte 千万亿字节 拍字节) = 1024TB

1EB（Exabyte 百亿亿字节 艾字节) = 1024PB

1ZB (Zettabyte 十万亿亿字节 泽字节) = 1024EB

1YB (Jottabyte 一亿亿亿字节 尧字节) = 1024ZB

1BB (Brontobyte 一千亿亿亿字节) = 1024YB
```